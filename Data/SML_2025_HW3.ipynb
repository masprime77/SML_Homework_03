{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DY8izeG8a9vK"
      },
      "source": [
        "## Task 1: Linear Regression\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfK0nkKAADVt"
      },
      "source": [
        "All the necessary imports. You are not allowed to import any additional functionality for this task."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "oM6TM5wk_KUb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boUU72KbAPYS"
      },
      "source": [
        "Please fill in all the ToDos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kjYG2Khe_SLt"
      },
      "outputs": [],
      "source": [
        "def f(x):\n",
        "    return x ** 3 + (x - .5) ** 2 + .5\n",
        "\n",
        "\n",
        "def sample_data(n, low, high, sigma):\n",
        "    x = np.random.rand(int(n)) * (high - low) + low\n",
        "    return x.reshape(-1, 1), f(x) + np.random.randn(int(n)) * sigma\n",
        "\n",
        "\n",
        "def visualize(X_train, y_train,\n",
        "              X_test=None, y_test=None,\n",
        "              X_val=None, y_val=None,\n",
        "              X_pred=None, y_pred=None, y_std_pred=None,\n",
        "              filename=None):\n",
        "    plt.plot(X_train, y_train, '.', color='k')\n",
        "    if X_test is not None and y_test is not None:\n",
        "        plt.plot(X_test, y_test, 'x', color='r')\n",
        "\n",
        "    if X_val is not None and y_val is not None:\n",
        "        plt.plot(X_val, y_val, '.', color='tab:orange')\n",
        "\n",
        "    if y_std_pred is not None:\n",
        "        for c in [1., 2., 3.]:\n",
        "            plt.fill_between(X_pred.squeeze(), y_pred - c * y_std_pred, y_pred + c * y_std_pred,\n",
        "                             color=(0, 0, 1, 0.05))\n",
        "\n",
        "    if X_pred is not None and y_pred is not None:\n",
        "        plt.plot(X_pred.squeeze(), y_pred, '-', color='b')\n",
        "\n",
        "    if filename:\n",
        "        plt.savefig(filename)\n",
        "    else:\n",
        "        plt.show()\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def RMSE(pred, gt):\n",
        "  #TASK 1a)\n",
        "  #ToDo: Compute Root Mean Square Error\n",
        "  RMSE = np.sqrt(np.mean((pred - gt) ** 2))\n",
        "  return RMSE\n",
        "\n",
        "\n",
        "def log_likelihood(mean, std, gt):\n",
        "  #ToDo: Compute the log-likelihood\n",
        "  var = std ** 2\n",
        "  log_likelihood = -0.5 * np.log(2 * np.pi * var) - 0.5 * ((gt - mean) ** 2) / var\n",
        "  return np.mean(log_likelihood)\n",
        "\n",
        "\n",
        "def add_bias(X):\n",
        "  #ToDo\n",
        "  #TASK 1a)\n",
        "  X_with_Bias = np.hstack([X, np.ones((X.shape[0], 1))])\n",
        "  return X_with_Bias\n",
        "\n",
        "\n",
        "def polynomial_features(X, degree):\n",
        "  #ToDo: Initalize the features array with the correct dimensions\n",
        "  n_samples = X.shape[0]\n",
        "  features = np.zeros((n_samples, degree))\n",
        "\n",
        "  #ToDo: Compute the polynomial representation of the given features\n",
        "  for i in range(degree):\n",
        "      features[:, i] = X[:, 0] ** (i + 1)\n",
        "  return features\n",
        "\n",
        "\n",
        "def squared_exponential_features(X, alpha, beta):\n",
        "  #ToDo: Initalize the features array with the correct dimensions\n",
        "\n",
        "  n = X.shape[0]\n",
        "  k = len(alpha)\n",
        "  features = np.zeros((n, k))\n",
        "  for i in range(n):\n",
        "      for j in range(k):\n",
        "          features[i, j] = np.exp(-0.5 * beta * (X[i, 0] - alpha[j]) ** 2)\n",
        "  return features\n",
        "\n",
        "\n",
        "class LinearRegression:\n",
        "    def __init__(self):\n",
        "        self.bias = None\n",
        "        self.w = None\n",
        "\n",
        "    def fit(self, X, y, lam, bias=True):\n",
        "        #TASK 1a)\n",
        "        #ToDo: Set bias if bias is present\n",
        "        self.bias = bias\n",
        "\n",
        "        #Todo: Add the bias to X\n",
        "        if self.bias:\n",
        "            X = add_bias(X)\n",
        "\n",
        "        #Todo: Fit the weights\n",
        "        I = np.eye(X.shape[1])\n",
        "        self.w = np.linalg.inv(X.T @ X + lam * I) @ X.T @ y\n",
        "\n",
        "    def predict(self, X_):\n",
        "        #TASK 1a)\n",
        "        #ToDo: Compute the prediciton\n",
        "        if self.bias:\n",
        "            X_ = add_bias(X_)\n",
        "\n",
        "        prediction = X_ @ self.w\n",
        "        return prediction\n",
        "\n",
        "\n",
        "class BayesianLinearRegression:\n",
        "    def __init__(self):\n",
        "        self.bias = None\n",
        "        self.lam = None\n",
        "        self.sigma = None\n",
        "        self.X = None\n",
        "        self.y = None\n",
        "        self.mu = None\n",
        "        self.Lambda = None\n",
        "        self.Lambda_inv = None\n",
        "\n",
        "    def fit(self, X, y, lam, sigma, bias=True):\n",
        "      #ToDo: Initialize the relevant attributes with the parameters\n",
        "        self.bias = bias\n",
        "        self.lam = lam\n",
        "        self.sigma = sigma\n",
        "\n",
        "        #ToDo: Add bias to X\n",
        "        if self.bias:\n",
        "            X = add_bias(X)\n",
        "\n",
        "        #Todo: Compute these values\n",
        "        n, d = X.shape\n",
        "        I = np.eye(d)\n",
        "\n",
        "        self.Lambda = lam * I + (1 / sigma**2) * X.T @ X\n",
        "        self.Lambda_inv = np.linalg.inv(self.Lambda)\n",
        "        self.mu = (1 / sigma**2) * self.Lambda_inv @ X.T @ y\n",
        "        self.X = X\n",
        "        self.y = y\n",
        "\n",
        "    def predict(self, X_):\n",
        "      #ToDo: Add bias to X\n",
        "        if self.bias:\n",
        "            X_ = add_bias(X_)\n",
        "\n",
        "        #ToDo: Compute these values\n",
        "        mean = X_ @ self.mu\n",
        "        std = np.sqrt(np.sum(X_ @ self.Lambda_inv * X_, axis=1)) * self.sigma\n",
        "        return mean, std\n",
        "\n",
        "    def log_marginal_likelihood(self):\n",
        "        n, k = self.X.shape\n",
        "        log_marginal = .5 * k * np.log(self.lam)\n",
        "        log_marginal -= n * np.log(self.sigma)\n",
        "        log_marginal -= .5 * np.sum((self.y - self.X @ self.mu) ** 2) / (self.sigma ** 2)\n",
        "        log_marginal += .5 * self.lam * self.mu.T @ self.mu\n",
        "        log_marginal -= .5 * np.linalg.slogdet(self.Lambda)[1]\n",
        "        log_marginal -= .5 * n * np.log(2 * np.pi)\n",
        "        return log_marginal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ceo0UXB2AbO6"
      },
      "source": [
        "Run this cell to execute your code and to generate all the plots. Don't forget to upload both datasets lin_reg_train.txt and lin_reg_test.txt."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "NU9qSvYvACMo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/Users/masprime77/Documents/TUDa/4_semester_SoSe25/SML/Homeworks/Homework_03/Data/lin_reg_test.txt\n",
            "Linear Features\n",
            "  Train RMSE: 0.4121780156736108\n",
            "  Test  RMSE: 0.38428816992597875\n",
            "\n",
            "Polynomial Features\n",
            "  Degree = 2\n",
            "  Train RMSE: 0.21201447265968612\n",
            "  Test  RMSE: 0.2168724271414873\n",
            "\n",
            "  Degree = 3\n",
            "  Train RMSE: 0.0870682129548175\n",
            "  Test  RMSE: 0.1083580371973804\n",
            "\n",
            "  Degree = 4\n",
            "  Train RMSE: 0.0870126130663818\n",
            "  Test  RMSE: 0.10666239820964406\n",
            "\n",
            "Bayesian Linear Regression\n",
            "  Train RMSE: 0.41217792591659724\n",
            "  Test  RMSE: 0.38434085452132954\n",
            "  Average Train Log-LLH: -27568.07867786533\n",
            "  Average Test  Log-LLH: -25265.407986599534\n",
            "\n",
            "Squared Exponential Features\n",
            "  Train RMSE: 0.0816094153080289\n",
            "  Test  RMSE: 0.14341009678374458\n",
            "  Average Train Log-LLH: -244.12272537111875\n",
            "  Average Test  Log-LLH: -225.88273995771985\n",
            "\n"
          ]
        }
      ],
      "source": [
        "if __name__ == '__main__':\n",
        "    sigma = 0.1\n",
        "    lam = 0.01\n",
        "\n",
        "    # load data\n",
        "    print(os.path.join(os.getcwd(), \"lin_reg_test.txt\"))\n",
        "    train = np.loadtxt(os.path.join(os.getcwd(), \"lin_reg_train.txt\"), delimiter=\" \", encoding=\"utf-8-sig\")\n",
        "    test = np.loadtxt(os.path.join(os.getcwd(), \"lin_reg_test.txt\"), delimiter=\" \", encoding=\"utf-8-sig\")\n",
        "    X_train = train[:, 0].reshape(-1, 1)\n",
        "    y_train = train[:, 1]\n",
        "    X_test = test[:, 0].reshape(-1, 1)\n",
        "    y_test = test[:, 1]\n",
        "    # for plots\n",
        "    X_pred = np.linspace(-1, 1, 100).reshape(-1, 1)\n",
        "    visualize(X_train, y_train, X_test=X_test, y_test=y_test,\n",
        "              filename=os.path.join(os.getcwd(), 'data.pdf'))\n",
        "\n",
        "    n_train = X_train.shape[0]\n",
        "    n_test = X_test.shape[0]\n",
        "\n",
        "    print(\"Linear Features\")\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_train, y_train, lam, bias=True)\n",
        "    print(\"  Train RMSE: {}\".format(RMSE(model.predict(X_train), y_train)))\n",
        "    print(\"  Test  RMSE: {}\".format(RMSE(model.predict(X_test), y_test)))\n",
        "    print()\n",
        "    y_pred = model.predict(X_pred)\n",
        "    visualize(X_train, y_train, X_pred=X_pred, y_pred=y_pred,\n",
        "              filename=os.path.join(os.getcwd(), 'linear.pdf'))\n",
        "\n",
        "    print(\"Polynomial Features\")\n",
        "    degrees = [2, 3, 4]\n",
        "    for degree in degrees:\n",
        "        print(\"  Degree = {}\".format(degree))\n",
        "        P_train = polynomial_features(X_train, degree)\n",
        "        P_test = polynomial_features(X_test, degree)\n",
        "        P_pred = polynomial_features(X_pred, degree)\n",
        "        model = LinearRegression()\n",
        "        model.fit(P_train, y_train, lam, bias=True)\n",
        "        print(\"  Train RMSE: {}\".format(RMSE(model.predict(P_train), y_train)))\n",
        "        print(\"  Test  RMSE: {}\".format(RMSE(model.predict(P_test), y_test)))\n",
        "        print()\n",
        "        y_pred = model.predict(P_pred)\n",
        "        visualize(X_train, y_train, X_pred=X_pred, y_pred=y_pred,\n",
        "                  filename=os.path.join(os.getcwd(), 'polynomial_{}.pdf'.format(degree)))\n",
        "\n",
        "    print(\"Bayesian Linear Regression\")\n",
        "    model = BayesianLinearRegression()\n",
        "    model.fit(X_train, y_train, lam, sigma, bias=True)\n",
        "    mean_pred_train, std_pred_train = model.predict(X_train)\n",
        "    mean_pred_test, std_pred_test = model.predict(X_test)\n",
        "    print(\"  Train RMSE: {}\".format(RMSE(mean_pred_train, y_train)))\n",
        "    print(\"  Test  RMSE: {}\".format(RMSE(mean_pred_test, y_test)))\n",
        "    print(\"  Average Train Log-LLH: {}\".format(log_likelihood(mean_pred_train, std_pred_train, y_train)))\n",
        "    print(\"  Average Test  Log-LLH: {}\".format(log_likelihood(mean_pred_test, std_pred_test, y_test)))\n",
        "    print()\n",
        "    y_pred, y_std_pred = model.predict(X_pred)\n",
        "    visualize(X_train, y_train, X_pred=X_pred, y_pred=y_pred, y_std_pred=y_std_pred,\n",
        "              filename=os.path.join(os.getcwd(), 'bayesian_linear.pdf'))\n",
        "\n",
        "    print(\"Squared Exponential Features\")\n",
        "    model = BayesianLinearRegression()\n",
        "    alpha = np.linspace(-0.9, 1, 20)\n",
        "    beta = 10.\n",
        "    SE_train = squared_exponential_features(X_train, alpha, beta)\n",
        "    SE_test = squared_exponential_features(X_test, alpha, beta)\n",
        "    SE_pred = squared_exponential_features(X_pred, alpha, beta)\n",
        "    model.fit(SE_train, y_train, lam, sigma, bias=True)\n",
        "    mean_pred_train, std_pred_train = model.predict(SE_train)\n",
        "    mean_pred_test, std_pred_test = model.predict(SE_test)\n",
        "    print(\"  Train RMSE: {}\".format(RMSE(mean_pred_train, y_train)))\n",
        "    print(\"  Test  RMSE: {}\".format(RMSE(mean_pred_test, y_test)))\n",
        "    print(\"  Average Train Log-LLH: {}\".format(log_likelihood(mean_pred_train, std_pred_train, y_train)))\n",
        "    print(\"  Average Test  Log-LLH: {}\".format(log_likelihood(mean_pred_test, std_pred_test, y_test)))\n",
        "    print()\n",
        "    y_pred, y_std_pred = model.predict(SE_pred)\n",
        "    visualize(X_train, y_train, X_pred=X_pred, y_pred=y_pred, y_std_pred=y_std_pred,\n",
        "              filename=os.path.join(os.getcwd(), 'bayesian_squared_exponential.pdf'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjZ3IaeCdGDd"
      },
      "source": [
        "## Task 2: Gaussian Process"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S5BkKzWZdImL"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MUciACmnoBUw"
      },
      "outputs": [],
      "source": [
        "def rbf_kernel(X1, X2, rbf_sigma=1):\n",
        "  \"\"\"\n",
        "  Compute the covariance matrix between sets of 1D points X1 and X2 using the RBF/Gaussian kernel.\n",
        "\n",
        "  Args:\n",
        "    X1: ndarray(m,)\n",
        "    X2: ndarray(n,)\n",
        "    rbf_sigma: kernel bandwidth (float)\n",
        "\n",
        "  Returns:\n",
        "    cov: ndarray(m, n)\n",
        "  \"\"\"\n",
        "  ## TODO: your code here\n",
        "  pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sw2fAQP7wqHH"
      },
      "outputs": [],
      "source": [
        "## RBF kernel test\n",
        "test_X1 = np.asarray([5, 9, 6])\n",
        "test_X2 = np.asarray([5, 9, 3, 4, 1])\n",
        "rbf_gt = [[1.0, 0.00033546262790251185, 0.1353352832366127, 0.6065306597126334, 0.00033546262790251185], [0.00033546262790251185, 1.0, 1.522997974471263e-08, 3.726653172078671e-06, 1.2664165549094176e-14], [0.6065306597126334, 0.011108996538242306, 0.011108996538242306, 0.1353352832366127, 3.726653172078671e-06]]\n",
        "rbf_gt = np.asarray(rbf_gt)\n",
        "\n",
        "print(\"RBF ground truth\")\n",
        "print(rbf_gt)\n",
        "\n",
        "print(\"RBF test\")\n",
        "print(rbf_kernel(test_X1, test_X2, rbf_sigma=1))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iZgLZF4joCbe"
      },
      "outputs": [],
      "source": [
        "np.random.seed(42) # fixed seed, do not change\n",
        "x = np.arange(0, 2*np.pi, 0.015) # test points\n",
        "## TODO: complete the ...\n",
        "y = ... # Target function\n",
        "s2 = ... # noise variance\n",
        "noise = ...\n",
        "t = y + noise # Observed target function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JOxSIgp5fJaw"
      },
      "outputs": [],
      "source": [
        "K = rbf_kernel(x, x) # squared exponential kernel\n",
        "\n",
        "# Intialize the GP mean and covariance with the correct shape\n",
        "m = np.zeros(x.shape) # GP mean\n",
        "S = K + s2*np.eye(K.shape[0]) # GP covariance\n",
        "\n",
        "# Initial GP without any training points\n",
        "plt.figure()\n",
        "plt.title('Number of observations: 0', fontsize=18)\n",
        "plt.grid('on')\n",
        "plt.plot(x, y, lw=2, color='blue')\n",
        "plt.plot(x, m, lw=2, color='red')\n",
        "plt.fill_between(x, m+2*np.sqrt(np.diag(S)), m-2*np.sqrt(np.diag(S)), facecolor='red', alpha=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SlCayiAzppHQ"
      },
      "outputs": [],
      "source": [
        "# At each iteration, sample the test point with the highest uncertainty as the new training point and update your GP mean and covariance.\n",
        "# Plot GP at iteration 1, 2, 5, 10, 15. The iteration should be equal to the number of sampled points, e.g. at iteration 5 there are 5 points sampled.\n",
        "# TODO: your code here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2ZnENK4At2k"
      },
      "source": [
        "## Task 6: Principal Component Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F7zuJw4BAyGl"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBbvpoIOBF1q"
      },
      "outputs": [],
      "source": [
        "data = np.loadtxt(os.path.join(os.getcwd(), 'iris.txt'), delimiter=',', encoding='utf-8-sig')\n",
        "n = data.shape[0]\n",
        "X = data[:,:-1] # last column denotes the class, so we ignore it\n",
        "\n",
        "#ToDo: normalize data\n",
        "X_mean = ...\n",
        "X_std = ...\n",
        "X_norm = ..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DsEOEx-aBH3n"
      },
      "outputs": [],
      "source": [
        "#ToDo: Compute Covariance matrix\n",
        "A = ...\n",
        "\n",
        "#ToDo: Compute Eigenvalues and Eigenvectors Hint: Check if Numpy has a function for this\n",
        "eigval, eigvec = ...\n",
        "\n",
        "idx = np.argsort(-eigval)\n",
        "eigval = eigval[idx]\n",
        "eigvec = eigvec[:,idx]\n",
        "\n",
        "#ToDo: Compute the variance explained by each eigenvalue Hint: Check if Numpy has a function for this\n",
        "explained_variance = ...\n",
        "\n",
        "#Hint: The resulting plot should resemble an elbow\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot([1,2,3,4],explained_variance)\n",
        "plt.xlabel('N. of components', fontsize=18)\n",
        "plt.ylabel('Explained variance', fontsize=18)\n",
        "plt.grid(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uu-FfC43BTNz"
      },
      "outputs": [],
      "source": [
        "#ToDo Compute the projection\n",
        "X_proj = ...\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "\n",
        "#Todo: Use the projected data to plot the 3 classes as scatter plots where each class has a different colour.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UAdhsM_lBcqE"
      },
      "outputs": [],
      "source": [
        "#ToDo: Initalize the normalized RMSE arrays with the correct dimensions\n",
        "nrmse = ...\n",
        "\n",
        "\n",
        "for i in range(0,...):\n",
        "  #ToDo: Compute the Projection of the data\n",
        "  X_proj = ...\n",
        "  #ToDo: Project the resulting data back\n",
        "  X_restored = ...\n",
        "  X_restored = ...\n",
        "\n",
        "\n",
        "  nrmse[i,:] = ...\n",
        "\n",
        "\n",
        "print(nrmse)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
